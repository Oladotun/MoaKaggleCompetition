{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Replication Keras Notebook\n\nI am simply using this notebook to learn the techniques Giorgos F demonstrated in his notebook at https://www.kaggle.com/giorgosfoukarakis/moa-eda-fastica-dnn-label-smoothing; if I can get that far, then I can look for ways to improve it.\n\nThis will also be an exercise in writing clearer documentation of my steps."},{"metadata":{},"cell_type":"markdown","source":"\n## GF's notes on experimenting with model parameters and pre/post processing data\n\n\"I tested various techniques and parameters during this work, some of them improved my LB significally.\n\n1. Using cp_type column : predictions after removing this feature were less accurate.\n1. Using Standard /Minmax scaling but Normal Quantile Transform before ICA lead to better predictions\n1. Label smoothing is definitely leading to improved scores due to the way of LB scoring system. Trying to use values larger than 0.001/0.999 for min/max lowered scores.\n1. Adding weight normalization was tested too but without any success\n1. Testing AdamW, LazyAdam optimizers, didn't improve results\n1. Testing Leaky_relu ,elu no obvious improvement\n1. Changing batch size from 128 up to 512 didn't change LB score (as expected)\n1. Using larger models : more hidden layers and/or nodes per layer up to 8192/2048 showed small improvement (possibly due to some extra overfitting)\n1. Tried batch normalization before the activation function, not suitable for our activations\n1. Tested different values for FastICA independent components\"\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport category_encoders as ce\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn import preprocessing as pp\nfrom sklearn.decomposition import FastICA\nfrom sklearn.model_selection import train_test_split, StratifiedKFold","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\nsns.set_style('whitegrid')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras.backend as K\nfrom keras import utils\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, Dense, Input, Dropout\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logloss(y_true,y_pred):\n    # y_pred = tf.clip_by_value(y_pred,1e-20,1-1e-20)\n    y_pred = tf.clip_by_value(y_pred,0.001,0.999)\n    return -K.mean(y_true*K.log(y_pred) + (1-y_true)*K.log(1-y_pred))","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading datasets\nI don't know why everyone doesn't load the data into a dataframe setting `sig_id` as the index... but no one does. Here's the rundown:\n* pandas read csv data and set index values to `sig_id`\n* set `cp_type` and `cp_dose` to categorical data. This isn't necessary. The `category_encoders` library doesn't actually pay attention to this. Still, I like the functionality and it's useful in other contexts.\n* `category_encoders.OrdinalEncoder` seeks out string columns and converts the labels to integers... starting from 1. Since `cp-type` and `cp_dose` only have two distinct labels, these are mapped to 1 and 2.\n* since nobody wants 1 and 2, I subtract 1 elementwise from each of these columns to get the desired 0 and 1 binary encoding.\n\nFun fact: I didn't use the `BinaryEncoder` because the documentation says, \"Binary encoding for categorical variables, similar to onehot, but stores categories as binary bitstrings.\" https://contrib.scikit-learn.org/category_encoders/binary.html No idea how that would play with Keras. I want integers: \"Encodes categorical features as ordinal, in one ordered feature. Ordinal encoding uses a single column of integers to represent the classes.\" https://contrib.scikit-learn.org/category_encoders/ordinal.html\n\nOur man GF does what I suspect is the normal thing and uses a `get_dummies` method (`pandas`' method; `sklearn` has one, too, which I use for clusters) which, if you `drop_first`, does the same thing, but by God I'm encoding a single column as integers, not transforming a single column into a number of columns, the second number just happening to also be one...\n\n* I use `MinMaxScaler` to map the times to -0.5, 0, +0.5 instead of literally using `.map` to make them 1, 2, 3 because, you know, neural nets and features centered at 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_df = pd.read_csv('../input/lish-moa/train_features.csv',index_col='sig_id')\ntts_df = pd.read_csv('../input/lish-moa/train_targets_scored.csv',index_col='sig_id')\ntf_df['cp_type']=tf_df['cp_type'].astype('category')\ntf_df['cp_dose']=tf_df['cp_dose'].astype('category')\nprint(tf_df['cp_type'].unique(),tf_df['cp_dose'].unique())\noenc = ce.ordinal.OrdinalEncoder()\ntf_df = oenc.fit_transform(tf_df)\ntf_df['cp_type']=tf_df['cp_type']-1\ntf_df['cp_dose']=tf_df['cp_dose']-1\ntf_df.info()","execution_count":6,"outputs":[{"output_type":"stream","text":"['trt_cp', 'ctl_vehicle']\nCategories (2, object): ['trt_cp', 'ctl_vehicle'] ['D1', 'D2']\nCategories (2, object): ['D1', 'D2']\n<class 'pandas.core.frame.DataFrame'>\nIndex: 23814 entries, id_000644bb2 to id_ffffdd77b\nColumns: 875 entries, cp_type to c-99\ndtypes: float64(872), int64(3)\nmemory usage: 159.2+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tts_df.info()","execution_count":7,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 23814 entries, id_000644bb2 to id_ffffdd77b\nColumns: 206 entries, 5-alpha_reductase_inhibitor to wnt_inhibitor\ndtypes: int64(206)\nmemory usage: 37.6+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"testf_df = pd.read_csv('../input/lish-moa/test_features.csv',index_col='sig_id')\ntestf_df['cp_type']=testf_df['cp_type'].astype('category')\ntestf_df['cp_dose']=testf_df['cp_dose'].astype('category')\ntestf_df = oenc.transform(testf_df)\ntestf_df['cp_type']=testf_df['cp_type']-1\ntestf_df['cp_dose']=testf_df['cp_dose']-1\ntestf_df.info()","execution_count":8,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 3982 entries, id_0004d9e33 to id_ffd5800b6\nColumns: 875 entries, cp_type to c-99\ndtypes: float64(872), int64(3)\nmemory usage: 26.6+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I imported sklearn.preprocessing with the unorthodox abbreviation pp\nscaler = pp.MinMaxScaler(feature_range=(-0.5,0.5))\ntf_df['cp_time']=scaler.fit_transform((np.array(tf_df['cp_time'])).reshape(-1,1))\ntestf_df['cp_time']=scaler.transform((np.array(testf_df['cp_time'])).reshape(-1,1))","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the first inexplicable thing our man GF does, immediately after reading in the data, is to... hey, I read the code a fourth time and saw it. He culls the columns that aren't all zeros from the `train_targets_nonscored` file and rams them onto the scored targets file. Interesting. I won't do that for now."},{"metadata":{},"cell_type":"markdown","source":"# EDA\n\nI did a bunch of EDA in an offline notebook (offline? heck, it's on Dotun's Moa repo on github) and saw pretty much what GF saw. His seaborn KDE plots do make things look clearer to assess all the gene and cell features at once.\n\nOne thing I don't remember seeing in my EDA was the high level of correlation between cell features. I DID notice, in the separated-pca notebooks where I broke gene and cell features apart to do PCA, was that 85% of the explained variance in the cell features was concentrated in the first PCA component, which I affectionately called the SCREECH KILL KILL component. This component has a negative coefficient for every feature and presumably represents broad spectrum toxicity. The concentration of variation in this single component is completely consistent with there being high intercorrelation between the cell features.\n\nGF gives some context on what agonists, antagonists, activators, and inhibitors are.\n\nHe presents some plots with the same info that Matt showed about how many rows / `sig_id`s / experiments have 0, 1, or more hits on the target MoAs. There are a *lot* of empty rows in the non-scored targets matrix."},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\n\nGF performs three stages of feature engineering:\n1. `VarianceThreshold`: Stack train and test features together, then select features with a threshold of 0.95. He interprets his procedure as \"So we will use data as is and try VarianceThreshold to detect and remove low variance features (we have already scaled our data). Target variability was set to 90% with trial and error.\" So far as I can tell, I'm certain he has NOT scaled the data yet, and he's selecting features with variance > 0.95 on the supplied -10 to +10 scale. I verified this by running his own notebook.\n1. `QuantileTransformer`: A brutal method to rescale a dataset to pull in outliers and produce an evenly distributed dataset, with the option to further transform this into a normally distributed dataset. He uses 100 quantiles and the normal option, just like the other source I consulted. The sklearn docs show an illustration of the results: https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#quantiletransformer-gaussian-output\n1. `FastICA`: A more sophisticated dimensionality reduction technique than PCA, which to read GF's references itself depends on a dedicated neural network routine. His notebook implies that he tried ICA with 80 gene components and 20 cell components, then scrapped that approach and went with 300 components across all floating point features. Having compared models with PCA analysis on gene and cell features together (actually, the whole dataset, `cp` features too) to models with PCA done on the split features, I think that leaving them together is the way to do it, even aside from the question of how many dimensions to use."},{"metadata":{"trusted":true},"cell_type":"code","source":"totalf_df = pd.concat([tf_df,testf_df],axis=0)\nweeder = VarianceThreshold(0.95)\n# high variance features retained\nhighvf_arr = weeder.fit_transform(totalf_df.loc[:,'g-0':'c-99'])\nhighvf_arr.shape","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"(27796, 717)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's plot a few features...\nfig, ax = plt.subplots(1,2)\nax[0].hist(x=highvf_arr[:,0])\nax[1].hist(x=highvf_arr[:,-1])\nplt.tight_layout()\nplt.show()","execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I imported sklearn.preprocessing with the unorthodox abbreviation pp\nleveller = pp.QuantileTransformer(n_quantiles=100,output_distribution='normal')\nhighvf_arr = leveller.fit_transform(highvf_arr)\nhighvf_arr.shape","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"(27796, 717)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's plot a few features...\nfig, ax = plt.subplots(1,2)\n# for some bloody reason this code just hung\n#sns.countplot(x=highvf_arr[:,0],ax=ax[0])\n#sns.countplot(x=highvf_arr[:,-1],ax=ax[1])\nax[0].hist(x=highvf_arr[:,0])\nax[1].hist(x=highvf_arr[:,-1])\nplt.tight_layout()\nplt.show()","execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAaQAAAEUCAYAAABkhkJAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAATF0lEQVR4nO3dX2hbddzH8U961nauWrrUtctwOCzOJ1pQiCgIu5jCKiPdFIRIcCD4B53KEIerom11iGZTdDCLXogXIl6MByqLQkXmhX9ANKhYo5vOVqaLLaaKY7J2y85zEdbqsz9JT9Keb07er6uZX07zOz9+n3zWk+wYcl3XFQAAPmvwewIAAEgUEgDACAoJAGAChQQAMIFCAgCYsMTvCVTT6dOndfz4cTU2NioUCvk9HQSM67o6efKkWlpa1NAQzL/LkSEspFIZClQhHT9+XIcOHfJ7Ggi4tWvX6pJLLvF7GguCDGExnC9DgSqkxsZGScWTbWpqOu/zRkdH1d3dvVjTMo21KCpnHWZmZnTo0KHZfRZE5WZIYu+cwTrMKbUWpTJUspBSqZRGRkb022+/af/+/Vq7dq0kaWxsTH19ffrrr7/U1tamVCqlNWvWLNhYOc5cYmhqalJzc/MFn1tqvJ6wFkXlroOXS1m1kqP5ZEhi75zBOswpZy3OmyG3hC+++MI9evSou379evfgwYOzj2/ZssUdHh52Xdd1h4eH3S1btizoWDlOnDjhfvnll+6JEycu+Lwvv/xyXj83yFiLonLWodz9dS61kqP5nCN7p4h1mFNqLUrtr5KfzF5//fWKRCL/eSyfzyubzSoej0uS4vG4stmspqamFmQMqHXkCCjN02dIuVxOnZ2dchxHkuQ4jjo6OpTL5eS6btXHwuFwNc4VMIUcAf8VqC81nDE6OlryOZlMZhFmUhtYiyLWYU45GZJYszNYhzmVrIWnQopEIpqYmFChUJDjOCoUCpqcnFQkEpHrulUfm6/u7u4LfrCWyWQUi8W8nHrgsBZF5azD9PR02W/U5bCco1IZktg7Z7AOc0qtRakMefrXfe3t7YpGo0qn05KkdDqtaDSqcDi8IGNAEJEj4P8p9a2JnTt3uuvWrXOj0ah70003uRs3bnRd13V/+ukn94477nA3bNjg3nHHHe7hw4dnj1mIsXLwLbv5Yy2KFvpbdrWSI75lN3+sw5xKv2UXct3g/A/6zvw6yCW78rEWRfO5ZFfO5axaNZ9zZO8UsQ5zyr1kd779FcwbctWhmZMFT8f9T/SaKs8EqC9eM+Q1s0EWyG/Z1aOmRke9j7077+P+94W4p9ebOVlQU6Pj6VjAIq97umXZUk/Z2//S5nkfE3QUUp3zWmSECUFDFvzHJTsAgAkUEgDABAoJAGAChQQAMIFCAgCYQCEBAEygkAAAJlBIAAATKCQAgAkUEgDABAoJAGAChQQAMIFCAgCYQCEBAEygkAAAJlBIAAATKCQAgAkUEgDABAoJAGAChQQAMIFCAgCYQCEBAEygkAAAJlBIAAATKCQAgAkUEgDABAoJAGAChQQAMIFCAgCYQCEBAEygkAAAJlBIAAATKCQAgAkUEgDABAoJAGAChQT47KOPPtJtt92mzZs3q7e3Vx988IEkaWxsTIlEQj09PUokEhofH589xusYYFnFhUSYAO9c19Xjjz+uXbt26d1339Xu3bu1Y8cOnT59WgMDA0omkxoZGVEymVR/f//scV7HAMsqKiTCBFSuoaFBx44dkyQdO3ZMHR0d+vPPP5XNZhWPxyVJ8Xhc2WxWU1NTyufznsYA6yr+DYkwAd6FQiG98sor2rp1q9avX6+HHnpIL7zwgnK5nDo7O+U4jiTJcRx1dHQol8t5HgOsW1LJwf8O07Jly3T8+HG9/vrrFwyF67qexsLhcNnzGh0dLfmcTCbj4YztisVii/6aQVtDP87n1KlTev311zU0NKRYLKZMJqNHH31Uu3btWvS5/Fs5GZKCtQfIUHVUck4VFZLVMHV3d6u5ufm845lMxpfNFzRBWsNy9sT09HTZb9Tl+v777zU5OTn72rFYTBdddJGam5s1MTGhQqEgx3FUKBQ0OTmpSCQi13U9jc1HqQxJ5KgagrZ+pfZEqQxVdMmunDBJ+k8oIpGIpzEgiFauXKnff/9dP//8syTp8OHD+uOPP3T55ZcrGo0qnU5LktLptKLRqMLhsNrb2z2NAdZV9BvSv8N0xRVXnDNMmzdvPisUXseAoFmxYoUGBwe1bds2hUIhSdLzzz+vtrY2DQ4Oqq+vT0NDQ2ptbVUqlZo9zusYYFlFhUSYgMpt2rRJmzZtOuvxrq4u7du375zHeB0DLKuokCTCBACoDu7UAAAwgUICAJhAIQEATKCQAAAmUEgAABMoJACACRQSAMAECgkAYAKFBAAwgUICAJhAIQEATKCQAAAmUEgAABMoJACACRQSAMAECgkAYAKFBAAwgUICAJhAIQEATKCQAAAmUEgAABMoJACACRQSAMAECgkAYAKFBAAwgUICAJhAIQEATKCQAAAmUEgAABMoJACACRQSAMAECgkAYAKFBAAwgUICAJhAIQEATKCQAAAmUEgAABMoJACACRUX0vT0tAYGBrRhwwb19vbq6aefliSNjY0pkUiop6dHiURC4+Pjs8d4HQOCiAwBRRUX0u7du9Xc3KyRkRHt379f27ZtkyQNDAwomUxqZGREyWRS/f39s8d4HQOCiAwBRRUV0vHjxzU8PKxt27YpFApJki699FLl83lls1nF43FJUjweVzab1dTUlOcxIIjIEDBnSSUHHzlyRG1tbdq7d68+//xztbS0aNu2bVq6dKk6OzvlOI4kyXEcdXR0KJfLyXVdT2PhcLjseY2OjpZ8TiaT8XDGdsVisUV/zaCtoR/nU8sZkoK1B8hQdVRyThUV0qlTp3TkyBFdffXV2rFjh7755hs98MAD2rNnTyU/tmLd3d1qbm4+73gmk/Fl8wVNkNawnD0xPT1d9ht1uWo1QxI5qoagrV+pPVEqQxUV0qpVq7RkyZLZywPXXnutli9frqVLl2piYkKFQkGO46hQKGhyclKRSESu63oaA4KIDAFzKvoMKRwO68Ybb9Snn34qqfjtnnw+rzVr1igajSqdTkuS0um0otGowuGw2tvbPY0BQUSGgDkV/YYkSc8884yefPJJpVIpLVmyRLt27VJra6sGBwfV19enoaEhtba2KpVKzR7jdQwIIjIEFFVcSKtXr9Zbb7111uNdXV3at2/fOY/xOgYEERkCirhTAwDABAoJAGAChQQAMIFCAgCYQCEBAEygkAAAJlBIAAATKCQAgAkUEgDABAoJAGAChQQAMIFCAgCYQCEBAEygkAAAJlBIAAATKCQAgAkUEgDABAoJAGAChQQAMIFCAgCYQCEBAEygkAAAJlBIAAATKCQAgAkUEgDABAoJAGAChQQAMIFCAgCYQCEBAEygkAAAJlBIAAATKCQAgAkUEgDABAoJAGAChQQAMIFCAgCYQCEBAEygkAAAJlStkPbu3aurrrpKhw4dkiSNjY0pkUiop6dHiURC4+Pjs8/1OgYEGRlCvatKIX333Xf6+uuvtWrVqtnHBgYGlEwmNTIyomQyqf7+/orHgKAiQ0AVCmlmZkbPPvusBgYGFAqFJEn5fF7ZbFbxeFySFI/Hlc1mNTU15XkMCCoyBBQtqfQH7NmzR5s2bdLq1atnH8vlcurs7JTjOJIkx3HU0dGhXC4n13U9jYXD4UqnCphEhoCiigrpq6++0rfffqvt27dXaz5VMTo6WvI5mUxmEWayeGKx2KK/ZtDW0I/zqeUMScHaA2SoOio5p4oK6YsvvtDPP/+sW265RZL0+++/65577tETTzyhiYkJFQoFOY6jQqGgyclJRSIRua7raWw+uru71dzcfN7xTCbjy+YLmiCtYTl7Ynp6uuw36nLVaoYkclQNQVu/UnuiVIYq+gzp/vvv1yeffKIDBw7owIEDWrlypd544w1t3LhR0WhU6XRakpROpxWNRhUOh9Xe3u5pDAgiMgTMqfgzpPMZHBxUX1+fhoaG1NraqlQqVfEYUE/IEOpNVQvpwIEDs3/u6urSvn37zvk8r2NA0JEh1DPu1AAAMIFCAgCYQCEBAEygkODJzMnCohwDoH4s2Lfs4M3MyYKaGh2/p1FSU6Oj3sfendcx+1/avECzAf6rFnLkdY61cG5eUUjGeHmjl3izB/6tFv7CRNbPxiU7AIAJFBIAwAQKCQBgAoUEADCBQgIAmEAhAQBMoJAAACZQSAAAEygkAIAJFBIAwAQKCQBgAoUEADCBQgIAmEAhAQBMoJAAACZQSAAAEygkAIAJFBIAwAQKCQBgAoUEADCBQgIAmEAhAQBMoJAAACZQSAAAEygkAIAJFBIAwAQKCQBgAoUEADCBQgIAmEAhAQBMoJAAACZQSAAAEyoqpD///FP33Xefenp61Nvbq4cfflhTU1OSpLGxMSUSCfX09CiRSGh8fHz2OK9jQBCRI6CookIKhUK69957NTIyov3792v16tV68cUXJUkDAwNKJpMaGRlRMplUf3//7HFex4AgIkdAUUWF1NbWphtvvHH2v6+77jodPXpU+Xxe2WxW8XhckhSPx5XNZjU1NeV5DAgqcgQULanWDzp9+rTeeecd3Xzzzcrlcurs7JTjOJIkx3HU0dGhXC4n13U9jYXD4WpNFTCLHKGeVa2Qdu7cqWXLlumuu+5SNput1o/1ZHR0tORzMpnMIsxk/mKxmN9TWFBW112yMTcrOSonQ5KNNTsXcuSfSuZWlUJKpVL65Zdf9Nprr6mhoUGRSEQTExMqFApyHEeFQkGTk5OKRCJyXdfT2Hx0d3erubn5vOOZTCbwG9Yqq+tezp6Ynp4u+43aC0s5KpUhiRz5yeq6l9oTpTJU8de+X375ZY2OjurVV19VU1OTJKm9vV3RaFTpdFqSlE6nFY1GFQ6HPY8BQUaOgAp/Q/rxxx/12muvac2aNbrzzjslSZdddpleffVVDQ4Oqq+vT0NDQ2ptbVUqlZo9zusYEETkCCiqqJCuvPJKHTx48JxjXV1d2rdvX1XHgCAiR0ARd2oAAJhAIQEATKCQAAAmUEgAABMoJACACRQSAMAECgkAYAKFBAAwgUICAJhAIQEATKCQAAAmUEgAABMoJACACRQSAMAECgkAYAKFBAAwgUICAJhAIQEATKCQAAAmUEgAABMoJACACRQSAMAECgkAYAKFBAAwgUICAJhAIQEATKCQAAAmUEgAABMoJACACRQSAMAECmmBzJws+D0FoOaRo7N5XZNaWMslfk8gqJoaHfU+9u68j9v/0uYFmI0NMycLamp0Fu041D5ydLYgrwmFhEUT5CABqByX7AAAJlBIAAATKCQAgAkUEgDABAoJAGAChQQAMMFkIY2NjSmRSKinp0eJRELj4+N+TwmoKWQItchkIQ0MDCiZTGpkZETJZFL9/f1+TwmoKWQItcjcP4zN5/PKZrN68803JUnxeFw7d+7U1NSUwuHwBY91XVeSNDMzU/J1pqenK59sCW0t87+7wPT0dGCPq+S1FkOp1zmzr87sM6sWK0NSsHJUCxmq9LjFcKHXKZWhkGssXaOjo9qxY4fee++92cc2btyo3bt365prrrngsceOHdOhQ4cWeoqoc2vXrtUll1zi9zTOiwzBuvNlyNxvSJVoaWnR2rVr1djYqFAo5Pd0EDCu6+rkyZNqaWnxeyoLhgxhIZXKkLlCikQimpiYUKFQkOM4KhQKmpycVCQSKXlsQ0OD6b+5ovYtXbrU7ymURIZg2YUyZO5LDe3t7YpGo0qn05KkdDqtaDRa8to3gCIyhFpl7jMkSTp8+LD6+vr0999/q7W1ValUSldccYXf0wJqBhlCLTJZSACA+mPukh0AoD5RSAAAEygkAIAJFBIAwARz/w5psfT19emzzz7T8uXLJUm33nqrHnzwQZ9ntXjGxsbU19env/76S21tbUqlUlqzZo3f0/LFzTffrKamJjU3N0uStm/frnXr1vk8q9pQzzkiQ3OqliG3Tu3YscN96623/J6Gb7Zs2eIODw+7ruu6w8PD7pYtW3yekX/Wr1/vHjx40O9p1KR6zhEZmlOtDHHJrg6duflmPB6XVLz5Zjab1dTUlM8zA2oDGVoYdV1Ib775pnp7e7V161YdPnzY7+ksmlwup87OTjlO8Y7BjuOoo6NDuVzO55n5Z/v27ert7dXg4KD+/vtvv6dTU+oxR2TobNXIUGA/Q7r99tt19OjRc4599tlnevTRR7VixQo1NDRoeHhY9957rz788MPZDYb68fbbbysSiWhmZkbPPfecnn32Wb344ot+T8sEcoRyVC1DVbh8GAg33HCD++uvv/o9jUXxxx9/uLFYzD116pTruq576tQpNxaLufl83ueZ+e+HH35w169f7/c0ala95IgMnV8lGarbS3YTExOzf/7444/V0NCgzs5OH2e0eLj55px//vlHx44dk1S8Nf7777+vaDTq86xqR73miAzNqWaG6vZednfffbfy+bxCoZAuvvhiPf7447ruuuv8ntai4eabRUeOHNEjjzyiQqGg06dPq6urS0899ZQ6Ojr8nlpNqOcckaGiamaobgsJAGBL3V6yAwDYQiEBAEygkAAAJlBIAAATKCQAgAkUEgDABAoJAGAChQQAMOH/ALPiQDcBiBAUAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Note that the data is still not standardized (mean 0, variance 1, or anything all that close). `QuantileTransformer(normal)` seems to shoehorn the data into a normal distribution with the same mean and variance as before."},{"metadata":{"trusted":true},"cell_type":"code","source":"ica = FastICA(n_components=300, max_iter=500)\nicaf_arr = ica.fit_transform(highvf_arr)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's plot a few features...\nfig, ax = plt.subplots(1,2)\nax[0].hist(x=icaf_arr[:,0])\nax[1].hist(x=icaf_arr[:,-1])\nplt.tight_layout()\nplt.show()","execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"So *that's* where the features get standardized-ish. Lemme check that."},{"metadata":{"trusted":true},"cell_type":"code","source":"icaf_df = pd.DataFrame(icaf_arr,index=totalf_df.index,\n                      columns=['ica'+str(i) for i in range(icaf_arr.shape[1])])\nica_ranges = icaf_df.max()-icaf_df.min()\nplt.hist(x=ica_ranges)\nplt.show()","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ica_means = icaf_df.mean()\nplt.hist(ica_means)\nplt.show()","execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Those are beyond standardized. I would think they're *too* small in variance; in any case, the means are decidedly 0.\n\nAt this point he rams these ICA features onto the right side of the original feature matrix. Wow, this is a common procedure. So much for getting *rid* of repetitive data; we're just complementing it with presumably more concentrated forms of the same features."},{"metadata":{"trusted":true},"cell_type":"code","source":"augmentf_df = pd.concat([totalf_df,icaf_df],axis=1)\naugtf_df = augmentf_df.iloc[:tf_df.shape[0],:]\naugtestf_df = augmentf_df.iloc[-testf_df.shape[0]:]\nassert len(augmentf_df) == len(augtf_df)+len(augtestf_df)","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So as far as I can tell, I'm still going to need to `StandardScale` the base gene and cell features. And yet if he doesn't, then I'd better not... for now. For now I just want to get in the vicinity of that tasty 0.01878 using thoroughly digested and understood and rephrased code. So far the only actual changes I know I have made are\n1. skipping adding the nonscored targets. Unless something in the network shows where he feeds that data in to inform predictions on the scored targets, that should make no difference. Tiny change if needed.\n1. mapping `cp_time` to -0.5 to +0.5 instead of 1 to 3. That should be a miniscule improvement and is in any case trivial to change.\n\nCode stockpile:\n\n`transformer = StandardScaler()\ntf_df.loc[:,'g-0':'c-99']=transformer.fit_transform(tf_df.loc[:,'g-0':'c-99'])`\n\n`testf_df.loc[:,'g-0':'c-99']=transformer.transform(testf_df.loc[:,'g-0':'c-99'])\ntestf_arr = np.array(testf_df)`"},{"metadata":{},"cell_type":"markdown","source":"Following both my own custom and GF's lead, let's explicitly create numpy arrays to hold the train, target, and test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_arr = augtf_df.values\ntestf_arr = augtestf_df.values\ntts_arr = tts_df.values","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_features = tf_arr.shape[1]\nn_labels = tts_arr.shape[1]\nn_train = tf_arr.shape[0]\nn_test = testf_arr.shape[0]","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model building\nGF sticks it into a function like the ones for `kerastuner`. Moreover, he implements a *k*-fold cross-validation that I will do my best to untangle and understand."},{"metadata":{"trusted":true},"cell_type":"code","source":"strategy = tf.distribute.get_strategy()\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","execution_count":21,"outputs":[{"output_type":"stream","text":"Number of accelerators:  1\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"He uses the *Sequential* mode in Keras [shudder]. Let's not do that."},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    def build_model(X, y):\n        '''Takes the train (or test) feature and label arrays\n        as parameters to set the dimensions of the input\n        and output layers.'''\n        K.clear_session()\n        inputs = Input(shape=(X.shape[1],))\n        x = BatchNormalization()(inputs)\n        x = Dropout(0.5)(x)\n        x = Dense(2048,activation='relu',\n                 input_shape=(X.shape[1],))(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(2048,activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        outputs = Dense(y.shape[1],activation='sigmoid')(x)\n        model = Model(inputs,outputs)\n        return model","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"He defines the following callbacks."},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_logloss', factor=0.3, \n                              patience=5, mode='min', min_lr=1E-5)\nearly_stopping = EarlyStopping(monitor='val_logloss', min_delta=1E-5, \n                               patience=15, mode='min',\n                               restore_best_weights=True)","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"He chooses different random seeds for each iteration of cross-validation. Note that with six seeds and five folds, he trains the model 30 times and gets an ensemble prediction. Velly inspirational. That should hack back a lot of overtraining. Since I'm going to fire and forget this notebook, let's do 10 seeds."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_seeds = 10\nnp.random.seed(84)\nseeds = np.random.randint(0,100,size=n_seeds)\nn_folds = 5","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we initialize a prediction array for submission and an out-of-fold tensor to hold an average out-of-fold score. I note with dismay that in the end this is still about half his... *half*...?  his actual submission score for the notebook. But as I note later, *he's scoring on all those extra targets*."},{"metadata":{"trusted":true},"cell_type":"code","source":"predts_arr = np.zeros((n_test,n_labels))\noof = 0.0\nhists = []","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here in the BCE options and coded into the `logloss` function at the top, note the 0.001 label smoothing parameter, not to be confused with the 0.001 (default) learning rate in Adam. I, personally, am going to dial the batch size down from 128 to 32, which I think is a default anyway. He claimed bigger batch sizes than 128 didn't make much difference, but I've observed fits to go up for smaller batch sizes when I was working on the NMR project."},{"metadata":{"trusted":true},"cell_type":"code","source":"# not sure if import from keras vs. tf.keras is significant\nopt = tf.keras.optimizers.Adam(lr=0.001, decay=0.001/200)\nbce = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001)\nn_batch = 32\nn_epochs = 40","execution_count":26,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here's where the magic happens, and I'm very happy I took the time to walk through and paraphrase his code.\n\nThat said, the nomenclature here worries me; I think it's non-standard and somewhat confusing. We are using the data that hitherto has been \"training\" data and splitting it via cross-validation to train and test the model. The \"y_val\" is not validation data in the ordinary sense; it's the prediction from each iteration of the model on that slice of test data, which is \"manually\" scored by calling our custom-written loss function on the test and prediction arrays. Meanwhile we are saving / aggregating predictions on the, back up a step, \"test\" data that we have to predict labels / targets for in order to submit a score to Kaggle. So \"test\" is ambiguous and \"validation\" is not being used in what I learned was the ordinary sense of a three-way split of train, test, and validate data.\n\n*That* said, here's what's going on.\n\n* Loop over all *seeds*.\n* Use the seed to initialize the data splitter. The cross-validation slices the data into a specified number of folds.\n* The inner loop loops over all the folds by turns. Each fold takes a turn being the holdout, test fold, and the rest of the data is placed in train for that iteration of the loop.\n* The splitter actually just supplies the appropriate groups of indices for the splits, which we then use to index the arrays of input and output data for training and testing.\n* The model is built and fit and its loss history is saved to a list of *dictionaries* of arrays.\n    * Something was broken with the callbacks and the validation data coming back in the keras history. Turns out you cannot put the validation datasets in a list, it *must* be a tuple... who knew?\n    * I am getting different losses, but of course I should get a different loss because he's scoring all those additional targets.\n* We save each model just in case...?\n* Compare predictions on the test features to the test labels and calculate a new out of fold score. Add this to the running average.\n* Calculate a new addition to our running prediction on the \"test\" data for the competition.\n* I added a per-fold report on the out of fold score to the overall report."},{"metadata":{},"cell_type":"markdown","source":"Something is very, very wrong with the running loss calculation. God, I hate tensor libraries. Why is the \"per trial\" loss continuing to accumulate?"},{"metadata":{"trusted":true},"cell_type":"code","source":"for seed in seeds:\n    print('\\nSeed value for this iteration:',seed,'\\n')\n    fold = 0\n    mltsplit = MultilabelStratifiedKFold(n_splits=n_folds,\n                                        shuffle=True,\n                                        random_state=seed)\n    for train, test in mltsplit.split(tf_arr, tts_arr):\n        X_train = tf_arr[train]\n        X_test = tf_arr[test]\n        y_train = tts_arr[train]\n        y_test = tts_arr[test]\n        model = build_model(X_train, y_train)\n        model.compile(optimizer=opt, loss=bce,metrics=[logloss])\n        history = model.fit(X_train, y_train, batch_size=n_batch,\n                           epochs=n_epochs, verbose=0,\n                           validation_data=(X_test,y_test),\n                           callbacks=[reduce_lr,early_stopping])\n        hists.append(history)\n        model.save('vqiks_model_seed'+str(seed)+'_fold'+str(fold))\n        y_val = model.predict(X_test)\n        # will average the out of fold score\n        # across all seeds, all folds\n        this_oof = (logloss(tf.constant(y_test,dtype=tf.float32),\n                      tf.constant(y_val,dtype=tf.float32))).numpy()\n        oof += this_oof / (n_folds * n_seeds)\n        # will average the predictions for submission\n        # across all seeds, all folds\n        predts_arr += model.predict(testf_arr)\n        print('For seed', seed, 'fold', fold,\n              'out of fold log loss is', this_oof)\n        fold += 1\nprint('Average out of fold log loss is', oof)","execution_count":30,"outputs":[{"output_type":"stream","text":"\nSeed value for this iteration: 42 \n\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=42 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n  FutureWarning)\n","name":"stderr"},{"output_type":"stream","text":"For seed 42 fold 0 out of fold log loss is 0.018814221\nFor seed 42 fold 1 out of fold log loss is 0.01931777\nFor seed 42 fold 2 out of fold log loss is 0.020017726\nFor seed 42 fold 3 out of fold log loss is 0.02100196\nFor seed 42 fold 4 out of fold log loss is 0.022735117\n\nSeed value for this iteration: 89 \n\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=89 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n  FutureWarning)\n","name":"stderr"},{"output_type":"stream","text":"For seed 89 fold 0 out of fold log loss is 0.02560702\nFor seed 89 fold 1 out of fold log loss is 0.029740566\nFor seed 89 fold 2 out of fold log loss is 0.03571226\nFor seed 89 fold 3 out of fold log loss is 0.04216683\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-a5f888e02c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                            callbacks=[reduce_lr,early_stopping])\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mhists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vqiks_model_seed'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_fold'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"Here we compile the scores for plotting. We should loop over seeds as well as folds, I think... will investigate that more later."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(hists[0].history['loss'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a big fat problem here, because the EarlyStopping kicks in sometimes and then the history winds up short and numpy spits out that dumbass cryptic \"can't be broadcast together\" error."},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_train = np.zeros(n_epochs)\nhist_val = np.zeros(n_epochs)\nfor i in range(n_folds):\n    delta = n_epochs - len(hists[i].history['loss'])\n    this_train = np.array(hists[i].history['loss'])\n    this_train = np.pad(this_train, (0,delta), (0,0))\n    hist_train += this_train / n_folds\n    this_val = np.array(hists[i].history['val_loss'])\n    this_val = np.pad(this_val, (0,delta), (0,0))\n    hist_val += this_val / n_folds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hists[0].history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.plot(hist_train)\nplt.plot(hist_val)\n#plt.yscale('log')\n#plt.yticks(ticks=[1,0.1,0.01,0.001,0.0001])\nplt.xlabel('Epochs')\nplt.ylabel('Averaged Loss')\nplt.legend(['Training','Validation'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"His creation of the prediction file is particularly confusing and roundabout. I think my existing solution works and is far more simple and straightforward."},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame(predts_arr,index=testf_df.index,\n                      columns=tts_df.columns)\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('/kaggle/working/submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}